{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDIT\n",
    "filename = \"C:/users/brend/Desktop/project3/MNIST_synthetic.h5\"\n",
    "\n",
    "f = h5py.File(filename,'r')\n",
    "\n",
    "keys = list(f.keys())\n",
    "\n",
    "testd = keys[0]\n",
    "traind = keys[1]\n",
    "trainl = keys[2]\n",
    "\n",
    "test_data = list(f[testd])\n",
    "\n",
    "\n",
    "train_data = list(f[traind])\n",
    "train_labels = list(f[trainl])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def find_digits(data):\n",
    "    regions = []\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    for dd in data:\n",
    "        im = Image.fromarray(dd[:,:,0])\n",
    "        im.show()\n",
    "\n",
    "        sub_reg = []\n",
    "\n",
    "        retval, threshold = cv2.threshold(dd, 1, 255, cv2.THRESH_BINARY)\n",
    "        rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "        threshed = cv2.morphologyEx(threshold, cv2.MORPH_CLOSE, rect_kernel)\n",
    "        contours, hierarchy = cv2.findContours(threshed, cv2.RETR_EXTERNAL,  \n",
    "                                                         cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        pts = []\n",
    "\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "            if h < 7 or h > 12 or len(cnt) == 1:\n",
    "                continue\n",
    "\n",
    "            pts.append((x,y))\n",
    "\n",
    "        for k in pts:\n",
    "            x = math.floor(k[0])\n",
    "            y = math.floor(k[1])\n",
    "\n",
    "            d = dd[y-1:y+12, x-1:x+11, 0]\n",
    "            \n",
    "            if d.shape[0] != 13 or d.shape != 12:\n",
    "                 d = np.resize(d, (13, 12))\n",
    "\n",
    "            if not d.any():\n",
    "                continue    \n",
    "            im = Image.fromarray(d)\n",
    "            im.show()\n",
    "            sub_reg.append(d)\n",
    "\n",
    "        i += 1\n",
    "        if i == 5:\n",
    "            break\n",
    "        regions.append(sub_reg)\n",
    "    return regions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(13, 12)\n"
     ]
    }
   ],
   "source": [
    "#check accuracy of number of digits found \n",
    "\n",
    "\n",
    "# print (len(tr_regs))\n",
    "tr_regs = find_digits(train_data)\n",
    "test_regs = find_digits(test_data)\n",
    "lll = []\n",
    "for t in tr_regs:\n",
    "    lll.append(len(t))\n",
    "\n",
    "ll = []\n",
    "for t in train_labels:\n",
    "    aa = []\n",
    "    for z in t:\n",
    "        if z != 10:\n",
    "            aa.append(z)\n",
    "    ll.append(len(aa))\n",
    "    \n",
    "\n",
    "b = 0\n",
    "\n",
    "for i in range(len(lll)):\n",
    "    if lll[i] != ll[i]:\n",
    "        b += 1\n",
    "\n",
    "print (b)\n",
    " \n",
    "print (tr_regs[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 12, 1)\n",
      "(167560, 13, 12, 1)\n",
      "167560\n",
      "[8, 5, 0, 3, 9, 7, 1, 2, 6, 4]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#make data so can be trained by single region MNIST digit\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "i = 0\n",
    "for t in tr_regs:\n",
    "    j = 0\n",
    "    for p in t:\n",
    "        if j >= len(train_labels[i]) or train_labels[i][j] == 10:\n",
    "            break\n",
    "        x_train.append(p.astype(\"float32\")/ 255) #normalize to [0,1]\n",
    "        y_train.append(train_labels[i][j])\n",
    "        j += 1\n",
    "    i += 1\n",
    "\n",
    "x_train = [np.expand_dims(np.array(xi),-1) for xi in x_train]\n",
    "x_train = np.expand_dims(x_train, 0)\n",
    "x_train = np.concatenate(x_train, axis=0)\n",
    "\n",
    "# y_train = [] \n",
    "# for t in train_labels:\n",
    "#     for n in t:\n",
    "#         if n != 10:\n",
    "#             y_train.append(n)\n",
    "cats = []\n",
    "for i in y_train:\n",
    "    if i not in cats:\n",
    "        cats.append(i)\n",
    "\n",
    "print (x_train[0].shape)\n",
    "print (x_train.shape)\n",
    "print (len(y_train))\n",
    "print (cats)\n",
    "print (len(cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner model for classifying single digits\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (13, 12, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "# x_train = x_train.astype(\"float32\") / 255\n",
    "# x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "\n",
    "# x_train = np.expand_dims(x_train, -1)\n",
    "# x_test = np.expand_dims(x_test, -1)\n",
    "# print(\"x_train shape:\", x_train.shape)\n",
    "# print(x_train.shape[0], \"train samples\")\n",
    "# print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 11, 10, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 19,466\n",
      "Trainable params: 19,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "13/13 [==============================] - 4s 314ms/step - loss: 2.1887 - accuracy: 0.2844 - val_loss: 2.1613 - val_accuracy: 0.3042\n",
      "Epoch 2/15\n",
      "13/13 [==============================] - 4s 313ms/step - loss: 2.1859 - accuracy: 0.2860 - val_loss: 2.1591 - val_accuracy: 0.3044\n",
      "Epoch 3/15\n",
      "13/13 [==============================] - 5s 397ms/step - loss: 2.1858 - accuracy: 0.2865 - val_loss: 2.1579 - val_accuracy: 0.3069\n",
      "Epoch 4/15\n",
      "13/13 [==============================] - 5s 372ms/step - loss: 2.1834 - accuracy: 0.2877 - val_loss: 2.1571 - val_accuracy: 0.3065\n",
      "Epoch 5/15\n",
      "13/13 [==============================] - 6s 437ms/step - loss: 2.1833 - accuracy: 0.2887 - val_loss: 2.1566 - val_accuracy: 0.3070\n",
      "Epoch 6/15\n",
      "13/13 [==============================] - 6s 450ms/step - loss: 2.1815 - accuracy: 0.2892 - val_loss: 2.1550 - val_accuracy: 0.3075\n",
      "Epoch 7/15\n",
      "13/13 [==============================] - 6s 449ms/step - loss: 2.1813 - accuracy: 0.2905 - val_loss: 2.1534 - val_accuracy: 0.3081\n",
      "Epoch 8/15\n",
      "13/13 [==============================] - 6s 436ms/step - loss: 2.1806 - accuracy: 0.2907 - val_loss: 2.1534 - val_accuracy: 0.3078\n",
      "Epoch 9/15\n",
      "13/13 [==============================] - 6s 448ms/step - loss: 2.1786 - accuracy: 0.2924 - val_loss: 2.1524 - val_accuracy: 0.3076\n",
      "Epoch 10/15\n",
      "13/13 [==============================] - 5s 405ms/step - loss: 2.1774 - accuracy: 0.2923 - val_loss: 2.1510 - val_accuracy: 0.3088\n",
      "Epoch 11/15\n",
      "13/13 [==============================] - 5s 416ms/step - loss: 2.1773 - accuracy: 0.2942 - val_loss: 2.1518 - val_accuracy: 0.3083\n",
      "Epoch 12/15\n",
      "13/13 [==============================] - 5s 381ms/step - loss: 2.1771 - accuracy: 0.2936 - val_loss: 2.1500 - val_accuracy: 0.3090\n",
      "Epoch 13/15\n",
      "13/13 [==============================] - 5s 396ms/step - loss: 2.1769 - accuracy: 0.2946 - val_loss: 2.1490 - val_accuracy: 0.3088\n",
      "Epoch 14/15\n",
      "13/13 [==============================] - 5s 371ms/step - loss: 2.1752 - accuracy: 0.2949 - val_loss: 2.1496 - val_accuracy: 0.3088\n",
      "Epoch 15/15\n",
      "13/13 [==============================] - 5s 387ms/step - loss: 2.1745 - accuracy: 0.2960 - val_loss: 2.1474 - val_accuracy: 0.3090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20127ac2160>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 12500\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print(\"Test loss:\", score[0])\n",
    "# print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
